# -*- coding: utf-8 -*-
"""SolarPanelDefect.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/11ErFuZEsmGPoiNMZPC3x3RQvBVhNM1aP
"""

!pip install -q kaggle



from google.colab import files
files.upload()

!mkdir ~/.kaggle
!cp kaggle.json ~/.kaggle/
!chmod 600 ~/.kaggle/kaggle.json

!kaggle datasets download -d pythonafroz/solar-panel-images

!unzip solar-panel-images.zip

import torch
from torch import nn
import torchvision.models as models

# Check if GPU is available
device = 'cuda' if torch.cuda.is_available() else 'cpu'
print(f'Using device: {device}')

from pathlib import Path
import os
import random
from PIL import Image

# random.seed(42)
image_path = Path("/content/Faulty_solar_panel")

# Adjust the glob pattern if necessary
image_path_list = list(image_path.rglob("*.jpg"))  # Search recursively for JPEG images

print(len(image_path_list))

if image_path_list:  # Check if any images were found
    random_image_path = random.choice(image_path_list)
    # ... rest of your code ...
else:
    print("No JPEG images found in the directory.")

import torchvision
from torchvision import datasets
import torchvision.transforms as transforms
from PIL import Image

print(torchvision.__version__)

# Transform image
data_transform = transforms.Compose([
    transforms.Resize(size = (128, 128)),         # Resize our images to 224x224
    transforms.ToTensor()
])

# Load the image
img = Image.open(random_image_path) # Use random_image_path instead of image_path

transformed_data = data_transform(img)
transformed_data, transformed_data.shape, transformed_data.dtype

# Setup source directory
source_dir = '/content/Faulty_solar_panel'

source_data = datasets.ImageFolder(root = source_dir,
                                  transform = data_transform, # Transforms input data into tensors
                                  target_transform = None)    # Transform labels into none

source_data

# Get class names as list and dict
class_names = source_data.classes
class_dict = source_data.class_to_idx
class_dict

# Split the dataset into training ,validating and testing sets
from torch.utils.data import random_split
train_size = int(0.8 * len(source_data))  # 80% for training
val_size = int(0.1 * len(source_data))  # 10% for validation
test_size = len(source_data) - train_size - val_size  # Remaining for testing

# Split the dataset
train_data, val_data, test_data = random_split(source_data, [train_size, val_size, test_size])

img, label = train_data[0]

img_permute = img.permute(1, 2, 0)
img.shape, img_permute.shape

# Visualizing using matplotliib
import numpy as np
import matplotlib.pyplot as plt
plt.figure(figsize = (3, 3))
plt.imshow(img_permute)
plt.axis("off")
plt.title(class_names[label], fontsize = 16);

from torch.utils.data import DataLoader

BATCH_SIZE = 32
train_dataloader = DataLoader(dataset = train_data,
                              batch_size = BATCH_SIZE,
                              num_workers = 1,
                              shuffle = True)
val_dataloader = DataLoader(dataset = val_data,
                              batch_size = BATCH_SIZE,
                              num_workers = 1,
                              shuffle = False)


test_dataloader = DataLoader(dataset = test_data,
                             batch_size = BATCH_SIZE,
                             num_workers = 1,
                             shuffle = False)

len(train_dataloader),len(test_dataloader) ,len(test_dataloader)

# Load the MobileNetV3 Large model pre-trained on ImageNet
model = models.mobilenet_v3_large(weights=models.MobileNet_V3_Large_Weights.IMAGENET1K_V1)

# Freeze the base model layers (optional if you want to fine-tune only the classifier)
for param in model.parameters():
    param.requires_grad = False

# Modify the classifier to match the number of classes in your dataset
num_ftrs = model.classifier[3].in_features
model.classifier[3] = nn.Linear(num_ftrs, len(class_names))

# Move the model to the appropriate device
model = model.to(device)

# Load the MobileNetV2 model pre-trained on ImageNet
model = models.mobilenet_v2(weights=models.MobileNet_V2_Weights.IMAGENET1K_V1)

# Freeze the base model layers (optional if you want to fine-tune only the classifier)
for param in model.parameters():
    param.requires_grad = False

# Modify the classifier to match the number of classes in your dataset
num_classes = len(class_names)  # Assuming class_names has already been defined
model.classifier[1] = nn.Linear(model.classifier[1].in_features, num_classes)

# Move the model to the device
model = model.to(device)

# Define training and testing steps (functions provided in your code)
def train_step(model, dataloader, loss_fn, optimizer):
    model.train()
    train_loss, train_acc = 0, 0

    for batch, (X, y) in enumerate(dataloader):
        X, y = X.to(device), y.to(device)
        y_pred = model(X)

        loss = loss_fn(y_pred, y)
        train_loss += loss.item()

        optimizer.zero_grad()
        loss.backward()
        optimizer.step()

        y_pred_class = torch.argmax(torch.softmax(y_pred, dim=1), dim=1)
        train_acc += (y_pred_class == y).sum().item() / len(y_pred)

    train_loss = train_loss / len(dataloader)
    train_acc = train_acc / len(dataloader)
    return train_loss, train_acc

def test_step(model, dataloader, loss_fn):
    model.eval()
    test_loss, test_acc = 0, 0

    with torch.inference_mode():
        for batch, (X, y) in enumerate(dataloader):
            X, y = X.to(device), y.to(device)

            test_pred_logits = model(X)
            loss = loss_fn(test_pred_logits, y)
            test_loss += loss.item()

            test_pred_labels = test_pred_logits.argmax(dim=1)
            test_acc += ((test_pred_labels == y).sum().item() / len(test_pred_labels))

    test_loss = test_loss / len(dataloader)
    test_acc = test_acc / len(dataloader)
    return test_loss, test_acc

def val_step(model, dataloader, loss_fn):
    model.eval()
    val_loss, val_acc = 0, 0

    with torch.inference_mode():
        for batch, (X, y) in enumerate(dataloader):
            X, y = X.to(device), y.to(device)

            val_pred_logits = model(X)
            loss = loss_fn(val_pred_logits, y)
            val_loss += loss.item()

            val_pred_labels = val_pred_logits.argmax(dim=1)
            val_acc += ((val_pred_labels == y).sum().item() / len(val_pred_labels))

    val_loss = val_loss / len(dataloader)
    val_acc = val_acc / len(dataloader)
    return val_loss, val_acc

# Define the optimizer
optimizer = torch.optim.Adam(model.parameters(), lr=0.001)

# Training loop
from tqdm.auto import tqdm
from timeit import default_timer as timer

# Define the loss function
loss_fn = nn.CrossEntropyLoss() # Add this line to define the loss function

EPOCHS = 15 # Define the number of epochs

def train(model, train_dataloader, test_dataloader, optimizer, loss_fn, epochs):
    results = {"train_loss": [], "train_acc": [], "test_loss": [], "test_acc": [], "val_loss": [], "val_acc": []} # Added "val_loss" and "val_acc" keys to the results dictionary

    for epoch in tqdm(range(epochs)):
        train_loss, train_acc = train_step(model, train_dataloader, loss_fn, optimizer)
        val_loss, val_acc = test_step(model, val_dataloader, loss_fn)

        print(f'Epoch: {epoch+1} | Train loss: {train_loss:.4f} - Train acc: {(train_acc*100):.2f}% - '
              f'val loss: {val_loss:.4f} - val acc: {(val_acc*100):.2f}%')

        results["train_loss"].append(train_loss)
        results["train_acc"].append(train_acc)
        results["val_loss"].append(val_loss) # Now you can append the validation loss
        results["val_acc"].append(val_acc) # Now you can append the validation accuracy

    return results

# Start training
start_time = timer()

model_results = train(model, train_dataloader, val_dataloader, optimizer, loss_fn, EPOCHS)

end_time = timer()
print(f'Total Train Time: {end_time - start_time:.3f} seconds')

# Access the results
model_results.keys()

# prompt: now as we have tested it with validation_data now its time to test it with test data , give code for it by reading all the above codes

# Define the loss function and optimizer
loss_fn = nn.CrossEntropyLoss()
optimizer = torch.optim.Adam(model.parameters(), lr=0.001)

# Set the number of epochs
EPOCHS = 1

# Evaluate the model on the test set
test_loss, test_acc = test_step(model, test_dataloader, loss_fn)
print(f'Test loss: {test_loss:.4f} - Test acc: {(test_acc*100):.2f}%')

# prompt: create a thing that it take input as image from user

from google.colab import files
from PIL import Image
import io

def predict_image_from_upload():
    uploaded = files.upload()
    for fn in uploaded.keys():
        image_bytes = uploaded[fn]
        image = Image.open(io.BytesIO(image_bytes))

        # Preprocess the image (same as during training)
        image = data_transform(image).unsqueeze(0).to(device)

        # Make a prediction
        model.eval()
        with torch.inference_mode():
            prediction = model(image)

        predicted_class = torch.argmax(prediction).item()
        class_name = class_names[predicted_class]

        print(f"The predicted class is: {class_name}")

# Example usage:
predict_image_from_upload()

# prompt: so i want to save a model that take image input from user and give the output

torch.save(model.state_dict(), 'solar_panel_classifier.pth')